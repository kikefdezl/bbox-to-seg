from __future__ import annotations

from pathlib import Path

import numpy as np
import torch.cuda
from segment_anything import build_sam, SamPredictor
from skimage import measure
from skimage.io import imread
from tqdm import tqdm

from bbox_to_seg import settings
from bbox_to_seg.coco import CocoDataset
from bbox_to_seg.utils import load_json, save_json, download_ckpt

CKPT_PATH = Path(settings.MODELS[settings.MODEL]["CKPT_PATH"])
IMAGE_EXTS = settings.IMAGE_EXTS
DEFAULT_OUTPUT_FILENAME = settings.DEFAULT_OUTPUT_FILENAME


def coco_bbox_to_coco_seg(
    coco_in: str | Path, image_folder_path: str | Path, coco_out: str | Path
):
    """
    Takes a COCO label and replaces the 'segmentation' camp with segmentations
    generated by SAM.

    :param coco_in: Path to the input COCO JSON file.
    :param image_folder_path: Path to the folder that contains the images.
    :param coco_out: Path to the folder to save the output COCO JSON file, or
    a full path containing the filename and .json extension.
    """
    data = load_json(coco_in)
    coco_dataset = CocoDataset(**data)

    output_filename = Path(coco_out)
    if output_filename.suffix.lower() != ".json":
        output_filename = output_filename / DEFAULT_OUTPUT_FILENAME

    if not CKPT_PATH.exists():
        download_ckpt()

    sam = build_sam(checkpoint=CKPT_PATH.as_posix())
    dev = "cuda" if torch.cuda.is_available() else "cpu"
    sam.to(device=dev)
    predictor = SamPredictor(sam)

    image_dir = Path(image_folder_path)

    for coco_image in tqdm(coco_dataset.images, "Images", position=0, leave=False):
        image_filepath = image_dir / coco_image.file_name
        annots = [a for a in coco_dataset.annotations if a.image_id == coco_image.id]
        image = imread(image_filepath.as_posix())
        predictor.set_image(image, image_format="BGR")
        for annotation in tqdm(annots, "Annotations", position=1, leave=False):
            bbox = np.array(
                [
                    annotation.bbox[0],
                    annotation.bbox[1],
                    annotation.bbox[0] + annotation.bbox[2],
                    annotation.bbox[1] + annotation.bbox[3],
                ]
            )
            mask = predictor.predict(box=bbox, multimask_output=False)[0][0]
            contours = measure.find_contours(mask.T, 0.5)
            if not contours:
                continue
            contour = contours[0]
            annotation.segmentation = [contour.flatten().tolist()]

    save_json(coco_dataset.dict(), output_filename)
    print(f"Saved auto-segmented JSON at: {output_filename.as_posix()}")
